{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "朴素贝叶斯(Naive Bayes, NB)和支持向量机(Support Vector Machines, SVM)的变体常被用作文本分类的基线方法，但它们的性能因模型变体、使用的特性和任务/数据集的不同而有很大差异。Sida Wang 和 Christopher D. Manning基于两种算法的特质，提出了NBSVM算法，实验证明，NBSVM在情绪分析数据集上优于大多数算法的结果，甚至有时能达到start-of-the-art,因此在文本分类中常被作为一个有用的baseline。本文将结合kaggle上的有毒评论分类任务详细介绍NBSVM算法。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**导入算法库**\n",
    "\n",
    "导入我们需要的算法库，如果你没有安装此算法库，可以pip安装一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**导入数据**\n",
    "\n",
    "导入有毒评论分类数据，该数据集可以在kaggle上下载，也可以在我的网盘上下载：https://share.weiyun.com/5c7KYLw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv').fillna(\" \") #填空行\n",
    "test = pd.read_csv('input/test.csv').fillna(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**查看数据**\n",
    "\n",
    "训练数据包含每行id、评论文本和6个我们将尝试预测的不同标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**分析评论文本数据的长度**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子长度的平均值: 67.86696204197504  句子长度的方差: 100.52020389688741  句子长度的最大值: 2273\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens = train.comment_text.map(lambda x: len(x.split(\" \")))\n",
    "print(\"句子长度的平均值:\",lens.mean(),\" 句子长度的方差:\", lens.std(), \" 句子长度的最大值:\",lens.max())\n",
    "lens.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>0.898321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "      <td>0.302226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate           none  \n",
       "count  159571.000000  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805       0.898321  \n",
       "std         0.216627       0.093420       0.302226  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       1.000000  \n",
       "50%         0.000000       0.000000       1.000000  \n",
       "75%         0.000000       0.000000       1.000000  \n",
       "max         1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "# train[label_cols].describe()\n",
    "train['none'] = 1-train[label_cols].max(axis=1)  #主要是看多少个评论没有表情\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**建立模型**\n",
    "\n",
    "我们首先对一列无意义的字符串正则匹配，去掉这些无意义的，利用tfidf提取单词的特征，使用ngram，得到1-ngram 或者2-ngram 特征，就像NBSVM论文中建议的那样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e316946aede2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m                \u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'unicode'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_idf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                smooth_idf=1, sublinear_tf=1 )\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrn_term_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"comment_text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtest_term_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"comment_text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1379\u001b[0m             \u001b[0mTf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0midf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m         \"\"\"\n\u001b[1;32m-> 1381\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1382\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m--> 869\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,analyzer='word',\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "trn_term_doc = vec.fit_transform(train[\"comment_text\"])\n",
    "test_term_doc = vec.transform(test[\"comment_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这将创建一个只有少量非零元素(存储在下面的表示中)的稀疏矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_term_doc, test_term_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**NBSVM模型**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trn_term_doc\n",
    "test_x = test_term_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是基本的朴素贝叶斯特征方程，公式可以参考论文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr(y_i, y):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)\n",
    "\n",
    "def get_mdl(y):\n",
    "    y = y.values\n",
    "    r = np.log(pr(1,y) / pr(0,y))\n",
    "    m = SVC(C=4,kernel='linear',probability=True)\n",
    "    x_nb = x.multiply(r)\n",
    "    return m.fit(x_nb, y), r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit toxic\n"
     ]
    }
   ],
   "source": [
    "preds = np.zeros((len(test), len(label_cols)))\n",
    "\n",
    "for i, j in enumerate(label_cols):\n",
    "    print('fit', j)\n",
    "    m,r = get_mdl(train[j])\n",
    "    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**参考**\n",
    "\n",
    "1、Wang S, Manning C D. Baselines and bigrams: Simple, good sentiment and topic classification[C]//Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume 2. Association for Computational Linguistics, 2012: 90-94.\n",
    "\n",
    "2、https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
